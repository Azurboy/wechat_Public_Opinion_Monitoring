"""
æ¯æ—¥æ—¥æŠ¥ç”Ÿæˆå™¨
ç”Ÿæˆèˆ†æƒ…ç›‘æµ‹æ—¥æŠ¥å¹¶æ¨é€åˆ°é£ä¹¦
æ”¯æŒLLMç”Ÿæˆæ™ºèƒ½ç®€æŠ¥
"""
from datetime import datetime
from typing import List, Dict, Optional
from collections import defaultdict
import logging

from crawlers.base import Article

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DailyReporter:
    """æ¯æ—¥æ—¥æŠ¥ç”Ÿæˆå™¨"""
    
    def __init__(self, use_llm: bool = True):
        """
        åˆå§‹åŒ–æ—¥æŠ¥ç”Ÿæˆå™¨
        
        Args:
            use_llm: æ˜¯å¦ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½ç®€æŠ¥
        """
        self.logger = logging.getLogger(self.__class__.__name__)
        self.use_llm = use_llm
        self._llm_client = None
    
    @property
    def llm_client(self):
        """å»¶è¿ŸåŠ è½½LLMå®¢æˆ·ç«¯"""
        if self._llm_client is None and self.use_llm:
            try:
                from utils.llm_client import LLMClient
                self._llm_client = LLMClient()
            except Exception as e:
                self.logger.warning(f"LLMå®¢æˆ·ç«¯åŠ è½½å¤±è´¥: {e}")
        return self._llm_client
    
    def generate_report(self, articles: List[Article], date: datetime = None) -> str:
        """
        ç”Ÿæˆæ—¥æŠ¥æ–‡æœ¬
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            date: æŠ¥å‘Šæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ—¥æŠ¥æ–‡æœ¬
        """
        if date is None:
            date = datetime.now()
        
        date_str = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        
        # ç»Ÿè®¡æ•°æ®
        stats = self._calculate_stats(articles)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_lines = [
            f"ğŸ“Š èˆ†æƒ…ç›‘æµ‹æ—¥æŠ¥ - {date_str}",
            "=" * 40,
            "",
            f"ğŸ“ˆ ä»Šæ—¥æ¦‚è§ˆ",
            f"â€¢ é‡‡é›†æ–‡ç« æ€»æ•°: {stats['total']} ç¯‡",
            "",
        ]
        
        # å¹³å°åˆ†å¸ƒ
        if stats['by_platform']:
            report_lines.append("ğŸ“± å¹³å°åˆ†å¸ƒ:")
            for platform, count in stats['by_platform'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                report_lines.append(f"  â€¢ {platform}: {count} ç¯‡ ({pct:.1f}%)")
            report_lines.append("")
        
        # å…³é”®è¯åˆ†å¸ƒ
        if stats['by_keyword']:
            report_lines.append("ğŸ”‘ å…³é”®è¯åˆ†å¸ƒ:")
            for keyword, count in stats['by_keyword'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                report_lines.append(f"  â€¢ {keyword}: {count} ç¯‡ ({pct:.1f}%)")
            report_lines.append("")
        
        # æƒ…æ„Ÿåˆ†æ
        if stats['by_sentiment']:
            report_lines.append("ğŸ’¬ æƒ…æ„Ÿåˆ†æ:")
            sentiment_emoji = {"ç§¯æ": "ğŸ˜Š", "æ¶ˆæ": "ğŸ˜Ÿ", "ä¸­ç«‹": "ğŸ˜"}
            for sentiment, count in stats['by_sentiment'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                emoji = sentiment_emoji.get(sentiment, "")
                report_lines.append(f"  â€¢ {emoji} {sentiment}: {count} ç¯‡ ({pct:.1f}%)")
            report_lines.append("")
        
        # é‡ç‚¹å†…å®¹
        report_lines.append("ğŸ“Œ é‡ç‚¹å†…å®¹æ‘˜è¦:")
        report_lines.append("-" * 40)
        
        # æŒ‰æƒ…æ„Ÿåˆ†ç»„å±•ç¤º
        # å…ˆå±•ç¤ºæ¶ˆæå†…å®¹ï¼ˆéœ€è¦å…³æ³¨ï¼‰
        negative_articles = [a for a in articles if a.sentiment == "æ¶ˆæ"]
        if negative_articles:
            report_lines.append("")
            report_lines.append("âš ï¸ éœ€å…³æ³¨ï¼ˆæ¶ˆæå†…å®¹ï¼‰:")
            for i, article in enumerate(negative_articles[:3], 1):
                report_lines.append(f"  {i}. {article.title[:40]}...")
                report_lines.append(f"     æ¥æº: {article.author} | å…³é”®è¯: {article.keyword}")
        
        # å±•ç¤ºç§¯æå†…å®¹
        positive_articles = [a for a in articles if a.sentiment == "ç§¯æ"]
        if positive_articles:
            report_lines.append("")
            report_lines.append("âœ… æ­£é¢æŠ¥é“:")
            for i, article in enumerate(positive_articles[:3], 1):
                report_lines.append(f"  {i}. {article.title[:40]}...")
                report_lines.append(f"     æ¥æº: {article.author} | å…³é”®è¯: {article.keyword}")
        
        report_lines.append("")
        report_lines.append("=" * 40)
        report_lines.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return "\n".join(report_lines)
    
    def _calculate_stats(self, articles: List[Article]) -> Dict:
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        stats = {
            "total": len(articles),
            "by_platform": defaultdict(int),
            "by_keyword": defaultdict(int),
            "by_sentiment": defaultdict(int),
        }
        
        for article in articles:
            stats["by_platform"][article.platform] += 1
            stats["by_keyword"][article.keyword] += 1
            if article.sentiment:
                stats["by_sentiment"][article.sentiment] += 1
        
        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸å¹¶æ’åº
        stats["by_platform"] = dict(sorted(stats["by_platform"].items(), key=lambda x: x[1], reverse=True))
        stats["by_keyword"] = dict(sorted(stats["by_keyword"].items(), key=lambda x: x[1], reverse=True))
        stats["by_sentiment"] = dict(sorted(stats["by_sentiment"].items(), key=lambda x: x[1], reverse=True))
        
        return stats
    
    def generate_markdown_report(self, articles: List[Article], date: datetime = None) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„æ—¥æŠ¥
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            date: æŠ¥å‘Šæ—¥æœŸ
            
        Returns:
            Markdownæ ¼å¼çš„æ—¥æŠ¥
        """
        if date is None:
            date = datetime.now()
        
        date_str = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        stats = self._calculate_stats(articles)
        
        md_lines = [
            f"# èˆ†æƒ…ç›‘æµ‹æ—¥æŠ¥ - {date_str}",
            "",
            "## ğŸ“ˆ ä»Šæ—¥æ¦‚è§ˆ",
            "",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| é‡‡é›†æ–‡ç« æ€»æ•° | {stats['total']} ç¯‡ |",
            "",
        ]
        
        # å¹³å°åˆ†å¸ƒè¡¨æ ¼
        if stats['by_platform']:
            md_lines.append("## ğŸ“± å¹³å°åˆ†å¸ƒ")
            md_lines.append("")
            md_lines.append("| å¹³å° | æ•°é‡ | å æ¯” |")
            md_lines.append("|------|------|------|")
            for platform, count in stats['by_platform'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                md_lines.append(f"| {platform} | {count} | {pct:.1f}% |")
            md_lines.append("")
        
        # å…³é”®è¯åˆ†å¸ƒè¡¨æ ¼
        if stats['by_keyword']:
            md_lines.append("## ğŸ”‘ å…³é”®è¯åˆ†å¸ƒ")
            md_lines.append("")
            md_lines.append("| å…³é”®è¯ | æ•°é‡ | å æ¯” |")
            md_lines.append("|--------|------|------|")
            for keyword, count in stats['by_keyword'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                md_lines.append(f"| {keyword} | {count} | {pct:.1f}% |")
            md_lines.append("")
        
        # æƒ…æ„Ÿåˆ†æ
        if stats['by_sentiment']:
            md_lines.append("## ğŸ’¬ æƒ…æ„Ÿåˆ†æ")
            md_lines.append("")
            md_lines.append("| æƒ…æ„Ÿ | æ•°é‡ | å æ¯” |")
            md_lines.append("|------|------|------|")
            for sentiment, count in stats['by_sentiment'].items():
                pct = count / stats['total'] * 100 if stats['total'] else 0
                md_lines.append(f"| {sentiment} | {count} | {pct:.1f}% |")
            md_lines.append("")
        
        # é‡ç‚¹å†…å®¹åˆ—è¡¨
        md_lines.append("## ğŸ“Œ é‡ç‚¹å†…å®¹")
        md_lines.append("")
        
        negative_articles = [a for a in articles if a.sentiment == "æ¶ˆæ"]
        if negative_articles:
            md_lines.append("### âš ï¸ éœ€å…³æ³¨ï¼ˆæ¶ˆæå†…å®¹ï¼‰")
            md_lines.append("")
            for i, article in enumerate(negative_articles[:5], 1):
                md_lines.append(f"{i}. **{article.title}**")
                md_lines.append(f"   - æ¥æº: {article.author}")
                md_lines.append(f"   - å…³é”®è¯: {article.keyword}")
                md_lines.append(f"   - [æŸ¥çœ‹åŸæ–‡]({article.url})")
                md_lines.append("")
        
        positive_articles = [a for a in articles if a.sentiment == "ç§¯æ"]
        if positive_articles:
            md_lines.append("### âœ… æ­£é¢æŠ¥é“")
            md_lines.append("")
            for i, article in enumerate(positive_articles[:5], 1):
                md_lines.append(f"{i}. **{article.title}**")
                md_lines.append(f"   - æ¥æº: {article.author}")
                md_lines.append(f"   - å…³é”®è¯: {article.keyword}")
                md_lines.append(f"   - [æŸ¥çœ‹åŸæ–‡]({article.url})")
                md_lines.append("")
        
        md_lines.append("---")
        md_lines.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        
        return "\n".join(md_lines)
    
    def generate_llm_briefing(self, articles: List[Article]) -> Optional[str]:
        """
        ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½èˆ†æƒ…ç®€æŠ¥
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            
        Returns:
            LLMç”Ÿæˆçš„ç®€æŠ¥æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.use_llm:
            self.logger.info("LLMåŠŸèƒ½æœªå¯ç”¨")
            return None
        
        if not self.llm_client or not self.llm_client.is_configured():
            self.logger.warning("LLMå®¢æˆ·ç«¯æœªé…ç½®")
            return None
        
        return self.llm_client.generate_briefing(articles, style="executive")
    
    def generate_full_report(self, articles: List[Article], date: datetime = None) -> str:
        """
        ç”Ÿæˆå®Œæ•´æ—¥æŠ¥ï¼ˆåŸºç¡€æŠ¥å‘Š + LLMç®€æŠ¥ï¼‰
        
        Args:
            articles: æ–‡ç« åˆ—è¡¨
            date: æŠ¥å‘Šæ—¥æœŸ
            
        Returns:
            å®Œæ•´çš„æ—¥æŠ¥æ–‡æœ¬
        """
        # åŸºç¡€æŠ¥å‘Š
        base_report = self.generate_report(articles, date)
        
        # å°è¯•ç”ŸæˆLLMç®€æŠ¥
        llm_briefing = self.generate_llm_briefing(articles)
        
        if llm_briefing:
            # å°†LLMç®€æŠ¥æ”¾åœ¨å¼€å¤´
            full_report = f"""ğŸ¤– AIæ™ºèƒ½ç®€æŠ¥
{'='*40}
{llm_briefing}

{'='*40}

{base_report}"""
            return full_report
        
        return base_report


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    from crawlers.base import Article
    from datetime import datetime
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_articles = [
        Article(
            title="ç ºæ€èµ„æœ¬å®Œæˆæ–°ä¸€è½®èèµ„ï¼Œå¸ƒå±€AIèµ›é“",
            author="æŠ•èµ„ç•Œ",
            content="ç ºæ€èµ„æœ¬å®£å¸ƒå®Œæˆæ–°ä¸€è½®èèµ„...",
            url="https://example.com/1",
            platform="å¾®ä¿¡å…¬ä¼—å·",
            keyword="ç ºæ€èµ„æœ¬",
            sentiment="ç§¯æ",
            sentiment_score=0.85,
        ),
        Article(
            title="Monolithäº§å“å‘å¸ƒä¼šåœ†æ»¡æˆåŠŸ",
            author="ç§‘æŠ€æ—¥æŠ¥",
            content="Monolithæœ€æ–°äº§å“å‘å¸ƒ...",
            url="https://example.com/2",
            platform="å¾®ä¿¡å…¬ä¼—å·",
            keyword="Monolith",
            sentiment="ç§¯æ",
            sentiment_score=0.92,
        ),
        Article(
            title="å¸‚åœºè§‚å¯Ÿï¼šæŠ•èµ„è¡Œä¸šé¢ä¸´æŒ‘æˆ˜",
            author="è´¢ç»è§‚å¯Ÿ",
            content="è¿‘æœŸå¸‚åœºæ³¢åŠ¨è¾ƒå¤§...",
            url="https://example.com/3",
            platform="å¾®ä¿¡å…¬ä¼—å·",
            keyword="ç ºæ€èµ„æœ¬",
            sentiment="æ¶ˆæ",
            sentiment_score=0.25,
        ),
        Article(
            title="æ›¹æ›¦å‡ºå¸­è¡Œä¸šè®ºå›å¹¶å‘è¡¨æ¼”è®²",
            author="ç»æµè§‚å¯Ÿ",
            content="æ›¹æ›¦åœ¨è®ºå›ä¸Šåˆ†äº«äº†...",
            url="https://example.com/4",
            platform="å¾®ä¿¡å…¬ä¼—å·",
            keyword="æ›¹æ›¦",
            sentiment="ä¸­ç«‹",
            sentiment_score=0.55,
        ),
    ]
    
    # ç”Ÿæˆæ—¥æŠ¥
    reporter = DailyReporter()
    report = reporter.generate_report(test_articles)
    print(report)

